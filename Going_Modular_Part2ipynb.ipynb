{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeZo34NzoErzPpyuoyunxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1ee0d10a16047118c51fd903b142b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_007e079dff4441ff83d843473fa8c49e",
              "IPY_MODEL_1db5768c099a469ca33688af819abf89",
              "IPY_MODEL_061edc2994fe4b0099c2605ae573ba41"
            ],
            "layout": "IPY_MODEL_bb227aa6a2f74eca83b6f0cfb07f466d"
          }
        },
        "007e079dff4441ff83d843473fa8c49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71813d1a2ea84dcfa8dc31f393d7e08b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a146193c104ccf9a7450c1461df978",
            "value": "100%"
          }
        },
        "1db5768c099a469ca33688af819abf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bb4408b711b489b8933b8e520c55fd8",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9846c8241db407ea1ea0628593ce673",
            "value": 5
          }
        },
        "061edc2994fe4b0099c2605ae573ba41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec8f81a996814722a67e1167296f46a8",
            "placeholder": "​",
            "style": "IPY_MODEL_4fadaa9426f04befbbf0c432a7fcba21",
            "value": " 5/5 [00:12&lt;00:00,  2.34s/it]"
          }
        },
        "bb227aa6a2f74eca83b6f0cfb07f466d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71813d1a2ea84dcfa8dc31f393d7e08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a146193c104ccf9a7450c1461df978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bb4408b711b489b8933b8e520c55fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9846c8241db407ea1ea0628593ce673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec8f81a996814722a67e1167296f46a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fadaa9426f04befbbf0c432a7fcba21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColinCMach/LearningPytorch/blob/main/Going_Modular_Part2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZWCjIh0EyVd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"going_modular\", exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "#setup path to data folder\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path /\"pizza_steak_sushi\"\n",
        "\n",
        "# if the image folder does not exist, download it and prepare it\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} already exists \")\n",
        "else:\n",
        "  print(f\"did not find{image_path} directory, creating one\")\n",
        "  image_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        " # downloading the pizza, steak, sushi data\n",
        "with open(data_path/\"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "   request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "   print(\"downloading the data\")\n",
        "   f.write(request.content)\n",
        "\n",
        "# Unzipping the pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path/\"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"unzipping the data\")\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "os.remove(\"/content/data/pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc3seMwsFFOz",
        "outputId": "4b2ec92e-5319-49d2-ceeb-8164814b4a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "did not finddata/pizza_steak_sushi directory, creating one\n",
            "downloading the data\n",
            "unzipping the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path /\"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "train_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMSWF3kOI8hL",
        "outputId": "289de1bb-3275-4e5e-83f8-3132c0884bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi/train')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset amd dataloaders\n"
      ],
      "metadata": {
        "id": "69lIO9YoIAxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "# create simple stransforms\n",
        "\n",
        "data_transform = transforms.Compose([transforms.Resize(size = (64,64)), transforms.ToTensor() ])\n",
        "\n",
        "# USe the imagefolder to create a dataset(s)\n",
        "train_data = datasets.ImageFolder(root = train_dir, transform = data_transform, target_transform = None)\n",
        "test_data = datasets.ImageFolder(root = test_dir, transform = data_transform)\n",
        "\n"
      ],
      "metadata": {
        "id": "FwCs7IEXHGq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes"
      ],
      "metadata": {
        "id": "ftZvedB4NvKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = train_data.class_to_idx\n",
        "class_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIiSaw5tVWi6",
        "outputId": "3e8194c3-d3df-4c17-d84c-323592dbefff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "train_dataloader = DataLoader(batch_size = BATCH_SIZE, dataset = train_data, num_workers = NUM_WORKERS,shuffle = True)\n",
        "test_dataloader = DataLoader(batch_size = BATCH_SIZE , num_workers = NUM_WORKERS, dataset = test_data, shuffle = False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "YO8qi2o6VhfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce0618c-1677-4b28-f5a9-9bb243cdea5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f2730e81590>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f2730e815d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creatae dataset and dataloaders \n",
        "Rather than rewriting all of the code above we wanted to load the data we can turn it inco a script called data_setup.py\n",
        "\n",
        "Lets capture all of the above functionality called create_dataloader()"
      ],
      "metadata": {
        "id": "mHdt_4CUhWp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "#Contains functionality for creating pytorch dataloders for image classifcation data\n",
        "\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloders(train_dir: str, test_dir:str, transform:transforms.Compose,batch_size:int, num_workers:int=NUM_WORKERS):\n",
        "  train_data = datasets.ImageFolder(train_dir, transform = transform)\n",
        "  test_data = datasets.ImageFolder(test_dir, transform = transform)\n",
        "\n",
        "  # get the class class_names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  # Turn the images into DataLoader\n",
        "  train_dataloader = DataLoader(train_data, batch_size = batch_size , num_workers = NUM_WORKERS,shuffle = True, pin_memory = True)\n",
        "  test_dataloader = DataLoader(test_data, batch_size = batch_size , num_workers = NUM_WORKERS, shuffle = False, pin_memory = True)\n",
        "  return train_dataloader, test_dataloader , class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSTm5KbihoQg",
        "outputId": "881759be-5896-40f8-e0c4-a17d3e5aab3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch import nn \n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"Creates the TinyVGG architecture.\n",
        "\n",
        "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
        "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "    Args:\n",
        "    input_shape: An integer indicating number of input channels.\n",
        "    hidden_units: An integer indicating number of hidden units between layers.\n",
        "    output_shape: An integer indicating number of output units.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=input_shape, \n",
        "                    out_channels=hidden_units, \n",
        "                    kernel_size=3, \n",
        "                    stride=1, \n",
        "                    padding=0),  \n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units, \n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                        stride=2)\n",
        "        )\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          # Where did this in_features shape come from? \n",
        "          # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "          nn.Linear(in_features=hidden_units*13*13,\n",
        "                    out_features=output_shape)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_block_1(x)\n",
        "        x = self.conv_block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "        # return self.classifier(self.block_2(self.block_1(x))) # <- leverage the benefits of operator fusion\n"
      ],
      "metadata": {
        "id": "OOJ8eO9QhUdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Instantiate an instance of the model\n",
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
        "                  hidden_units=10, \n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3DSvMTOC5KZ",
        "outputId": "ae9e80ad-a84d-4f93-acb4-9dd0cf3ac218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. get a batch of images and labels from the dataloader\n",
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "import matplotlib.pyplot as plt\n",
        "print(img_batch.shape)\n",
        "img_single , label_single = img_batch[0].unsqueeze(dim = 0), label_batch[0]\n",
        "print(f\"single image shape:{img_single.shape}\")\n",
        "\n",
        "# perform the forward pass\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_logits = model_0(img_single)\n",
        "  print(f\"The model transform the raw prediction is these logits {y_logits}\")\n",
        "  print(f\" The dimensions after the forward pass are {y_logits.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocQOHZDRC9sv",
        "outputId": "31163ad5-5b97-4a88-cdb1-496b958d5211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 64, 64])\n",
            "single image shape:torch.Size([1, 3, 64, 64])\n",
            "The model transform the raw prediction is these logits tensor([[ 0.0208, -0.0019,  0.0095]])\n",
            " The dimensions after the forward pass are torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\"\"\"\n",
        "Contains PyTorch model code to instantiate a TinyVGG model.\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"Creates the TinyVGG architecture.\n",
        "\n",
        "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
        "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "    Args:\n",
        "    input_shape: An integer indicating number of input channels.\n",
        "    hidden_units: An integer indicating number of hidden units between layers.\n",
        "    output_shape: An integer indicating number of output units.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=input_shape, \n",
        "                    out_channels=hidden_units, \n",
        "                    kernel_size=3, \n",
        "                    stride=1, \n",
        "                    padding=0),  \n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units, \n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                        stride=2)\n",
        "        )\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          # Where did this in_features shape come from? \n",
        "          # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "          nn.Linear(in_features=hidden_units*13*13,\n",
        "                    out_features=output_shape)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_block_1(x)\n",
        "        x = self.conv_block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKy7Nr8uEanV",
        "outputId": "3c35399d-b1c8-4f7a-c925-2a9d29e6310c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from going_modular import model_builder\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Instantiate an instance of the model from the \"model_builder.py\" script\n",
        "torch.manual_seed(42)\n",
        "model_1 = model_builder.TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
        "                                hidden_units=10, \n",
        "                                output_shape=len(class_names)).to(device)\n",
        "model_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_huNMiPZOGhQ",
        "outputId": "fff1458a-10d8-4bf2-de8c-6f66c157178c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get a batch of images and labels from the DataLoader\n",
        "img_batch, label_batch = next(iter(train_dataloader))\n",
        "\n",
        "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
        "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
        "print(f\"Single image shape: {img_single.shape}\\n\")\n",
        "\n",
        "# 3. Perform a forward pass on a single image\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "    pred = model_1(img_single.to(device))\n",
        "    \n",
        "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
        "print(f\"Output logits:\\n{pred}\\n\")\n",
        "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
        "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
        "print(f\"Actual label:\\n{label_single}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er3tLF0imk7Q",
        "outputId": "6643f5ae-ec2a-408a-9c52-938342c27887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single image shape: torch.Size([1, 3, 64, 64])\n",
            "\n",
            "Output logits:\n",
            "tensor([[ 0.0208, -0.0019,  0.0095]])\n",
            "\n",
            "Output prediction probabilities:\n",
            "tensor([[0.3371, 0.3295, 0.3333]])\n",
            "\n",
            "Output prediction label:\n",
            "tensor([0])\n",
            "\n",
            "Actual label:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def train_step(model: torch.nn.Module, \n",
        "               dataloader: torch.utils.data.DataLoader, \n",
        "               loss_fn: torch.nn.Module, \n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to training mode and then\n",
        "  runs through all of the required training steps (forward\n",
        "  pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    \n",
        "    (0.1112, 0.8743)\n",
        "  \"\"\"\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "  \n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "  \n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send data to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss.item() \n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metric across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch \n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "vCcClfILnKdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module, \n",
        "              dataloader: torch.utils.data.DataLoader, \n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "  a forward pass on a testing dataset.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy). For example:\n",
        "    \n",
        "    (0.0223, 0.8985)\n",
        "  \"\"\"\n",
        "  # Put model in eval mode\n",
        "  model.eval() \n",
        "  \n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "  \n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in enumerate(dataloader):\n",
        "          # Send data to target device\n",
        "          X, y = X.to(device), y.to(device)\n",
        "  \n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(X)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, y)\n",
        "          test_loss += loss.item()\n",
        "          \n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "          \n",
        "  # Adjust metrics to get average loss and accuracy per batch \n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "3ZQq9Sy-O0GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module, \n",
        "          train_dataloader: torch.utils.data.DataLoader, \n",
        "          test_dataloader: torch.utils.data.DataLoader, \n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List[float]]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for \n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]} \n",
        "    For example if training for epochs=2: \n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]} \n",
        "  \"\"\"\n",
        "  # Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": []\n",
        "  }\n",
        "  \n",
        "  # Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "      test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "      \n",
        "      # Print out what's happening\n",
        "      print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "      # Update results dictionary\n",
        "      results[\"train_loss\"].append(train_loss)\n",
        "      results[\"train_acc\"].append(train_acc)\n",
        "      results[\"test_loss\"].append(test_loss)\n",
        "      results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "MPyijX_-QLxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(model: torch.nn.Module, \n",
        "               dataloader: torch.utils.data.DataLoader, \n",
        "               loss_fn: torch.nn.Module, \n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to training mode and then\n",
        "  runs through all of the required training steps (forward\n",
        "  pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "    \n",
        "    (0.1112, 0.8743)\n",
        "  \"\"\"\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "  \n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "  \n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send data to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss.item() \n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metric across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch \n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module, \n",
        "              dataloader: torch.utils.data.DataLoader, \n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "  a forward pass on a testing dataset.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy). For example:\n",
        "    \n",
        "    (0.0223, 0.8985)\n",
        "  \"\"\"\n",
        "  # Put model in eval mode\n",
        "  model.eval() \n",
        "  \n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "  \n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in enumerate(dataloader):\n",
        "          # Send data to target device\n",
        "          X, y = X.to(device), y.to(device)\n",
        "  \n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(X)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, y)\n",
        "          test_loss += loss.item()\n",
        "          \n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "          \n",
        "  # Adjust metrics to get average loss and accuracy per batch \n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "\n",
        "def train(model: torch.nn.Module, \n",
        "          train_dataloader: torch.utils.data.DataLoader, \n",
        "          test_dataloader: torch.utils.data.DataLoader, \n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List[float]]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for \n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]} \n",
        "    For example if training for epochs=2: \n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]} \n",
        "  \"\"\"\n",
        "  # Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": []\n",
        "  }\n",
        "  \n",
        "  # Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "      test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "      \n",
        "      # Print out what's happening\n",
        "      print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "      # Update results dictionary\n",
        "      results[\"train_loss\"].append(train_loss)\n",
        "      results[\"train_acc\"].append(train_acc)\n",
        "      results[\"test_loss\"].append(test_loss)\n",
        "      results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAKwNpyAQYsY",
        "outputId": "db845439-dc54-4ed4-f6c3-db223acc929d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\"\"\"\n",
        "File containing various utility functions for PyTorch model training.\n",
        "\"\"\" \n",
        "import torch\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "  \"\"\"Saves a PyTorch model to a target directory.\n",
        "\n",
        "  Args:\n",
        "    model: A target PyTorch model to save.\n",
        "    target_dir: A directory for saving the model to.\n",
        "    model_name: A filename for the saved model. Should include\n",
        "      either \".pth\" or \".pt\" as the file extension.\n",
        "  \n",
        "  Example usage:\n",
        "    save_model(model=model_0,\n",
        "               target_dir=\"models\",\n",
        "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
        "  \"\"\"\n",
        "  # Create target directory\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "  \n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path / model_name\n",
        "\n",
        "  # Save the model state_dict()\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkOXXYx6Q1F-",
        "outputId": "f3ea9c4a-e9c5-4541-e413-55853a4ea2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "  \"\"\"Saves a PyTorch model to a target directory.\n",
        "\n",
        "  Args:\n",
        "    model: A target PyTorch model to save.\n",
        "    target_dir: A directory for saving the model to.\n",
        "    model_name: A filename for the saved model. Should include\n",
        "      either \".pth\" or \".pt\" as the file extension.\n",
        "  \n",
        "  Example usage:\n",
        "    save_model(model=model_0,\n",
        "               target_dir=\"models\",\n",
        "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
        "  \"\"\"\n",
        "  # Create target directory\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "  \n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path / model_name\n",
        "\n",
        "  # Save the model state_dict()\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "7vcOH9bNX48M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(42) \n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
        "                  hidden_units=10, \n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer \n",
        "start_time = timer()\n",
        "\n",
        "# Train model_0 \n",
        "model_0_results = train(model=model_0, \n",
        "                        train_dataloader=train_dataloader,\n",
        "                        test_dataloader=test_dataloader,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn, \n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
        "\n",
        "# Save the model\n",
        "save_model(model=model_0,\n",
        "           target_dir=\"models\",\n",
        "           model_name=\"05_going_modular_cell_mode_tinyvgg_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "c1ee0d10a16047118c51fd903b142b15",
            "007e079dff4441ff83d843473fa8c49e",
            "1db5768c099a469ca33688af819abf89",
            "061edc2994fe4b0099c2605ae573ba41",
            "bb227aa6a2f74eca83b6f0cfb07f466d",
            "71813d1a2ea84dcfa8dc31f393d7e08b",
            "a9a146193c104ccf9a7450c1461df978",
            "5bb4408b711b489b8933b8e520c55fd8",
            "f9846c8241db407ea1ea0628593ce673",
            "ec8f81a996814722a67e1167296f46a8",
            "4fadaa9426f04befbbf0c432a7fcba21"
          ]
        },
        "id": "Oh1-Whe8R1Jd",
        "outputId": "bec9973f-ed97-4f45-fa83-8cc9c979834e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ee0d10a16047118c51fd903b142b15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 1.1063 | train_acc: 0.3047 | test_loss: 1.0983 | test_acc: 0.2907\n",
            "Epoch: 2 | train_loss: 1.0995 | train_acc: 0.3320 | test_loss: 1.0698 | test_acc: 0.5417\n",
            "Epoch: 3 | train_loss: 1.0863 | train_acc: 0.4922 | test_loss: 1.0800 | test_acc: 0.5227\n",
            "Epoch: 4 | train_loss: 1.0825 | train_acc: 0.4102 | test_loss: 1.0599 | test_acc: 0.5729\n",
            "Epoch: 5 | train_loss: 1.0630 | train_acc: 0.4141 | test_loss: 1.0612 | test_acc: 0.5540\n",
            "[INFO] Total training time: 13.000 seconds\n",
            "[INFO] Saving model to: models/05_going_modular_cell_mode_tinyvgg_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOW ISTS TIME TO TRAIN AND EVALUALE THE SAME MODEL(SCIRPT MODE) -> TRAIN.PY\n",
        "\n",
        "LETS CREATE A FILE CALLED TRAIN.PY TO LEVERAGE ALL OF OUR OTHER CODE SCRPUTIS TO TRAIN A PYTORCH MODEL \n",
        "\n",
        "ESSENTIALLY WE WATNT TO REPLACE ALL OUF OUT FUNCVTIONALIOTY OF NOTEBOOK 04 IN ONE LINE"
      ],
      "metadata": {
        "id": "_LQE2QKUYngp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train.py \n",
        "\n",
        "# train a pytorch image classification modelk using device agnostic code\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import data_setup , engine , model_builder, utils\n",
        "\n",
        "# setup hyper parameters\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10 \n",
        "LR = 0.001\n",
        "\n",
        "# set upo directories\n",
        "train_dir = \"/content/data/pizza_steak_sushi/train\"\n",
        "test_dir = \"/content/data/pizza_steak_sushi/test\"\n",
        "\n",
        "# setr up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# create transforms\n",
        "data_transforms = transforms.Compose([transforms.Resize(size = (64,64)), \n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "# create dataloaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloders(train_dir = train_dir,\n",
        "                                                                              test_dir = test_dir,\n",
        "                                                                              transform = data_transforms,\n",
        "                                                                              batch_size = BATCH_SIZE)\n",
        "# create model\n",
        "model = model_builder.TinyVGG(3,10,len(class_names)).to(device)\n",
        "\n",
        "# set up loss and optimizer functions\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "# start the time\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# start training with help from the engine.oy\n",
        "engine.train(model = model, train_dataloader= train_dataloader, test_dataloader = test_dataloader, loss_fn = loss_fn,optimizer = optimizer, epochs = NUM_EPOCHS, device = device)\n",
        "end_time = timer()\n",
        "print(f\"INFO - Total training time :{end_time - start_time:.3f} seconds\")\n",
        "\n",
        "# save the model to a file\n",
        "utils.save_model(model = model, target_dir = \"models\", model_name = \"Saved_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91GVQJMoYRuc",
        "outputId": "6c4f556b-31c7-4535-cbd0-29f6e832600c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEye6NHIeu-n",
        "outputId": "ec2a5c35-e7b9-4d7a-98f5-a1a8b0088269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/20 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1080 | train_acc: 0.2734 | test_loss: 1.0909 | test_acc: 0.2708\n",
            "  5% 1/20 [00:01<00:37,  2.00s/it]Epoch: 2 | train_loss: 1.0922 | train_acc: 0.3750 | test_loss: 1.0966 | test_acc: 0.2708\n",
            " 10% 2/20 [00:04<00:36,  2.04s/it]Epoch: 3 | train_loss: 1.0843 | train_acc: 0.4062 | test_loss: 1.0904 | test_acc: 0.3324\n",
            " 15% 3/20 [00:06<00:34,  2.02s/it]Epoch: 4 | train_loss: 1.0748 | train_acc: 0.6133 | test_loss: 1.0805 | test_acc: 0.3722\n",
            " 20% 4/20 [00:08<00:32,  2.04s/it]Epoch: 5 | train_loss: 1.0493 | train_acc: 0.6055 | test_loss: 1.0471 | test_acc: 0.4612\n",
            " 25% 5/20 [00:10<00:30,  2.04s/it]Epoch: 6 | train_loss: 1.0486 | train_acc: 0.4727 | test_loss: 0.9903 | test_acc: 0.5559\n",
            " 30% 6/20 [00:12<00:28,  2.03s/it]Epoch: 7 | train_loss: 1.0524 | train_acc: 0.4531 | test_loss: 1.0393 | test_acc: 0.3409\n",
            " 35% 7/20 [00:14<00:26,  2.02s/it]Epoch: 8 | train_loss: 0.9459 | train_acc: 0.6016 | test_loss: 1.1241 | test_acc: 0.2917\n",
            " 40% 8/20 [00:16<00:26,  2.18s/it]Epoch: 9 | train_loss: 0.9354 | train_acc: 0.6406 | test_loss: 1.0503 | test_acc: 0.3627\n",
            " 45% 9/20 [00:19<00:26,  2.39s/it]Epoch: 10 | train_loss: 0.8712 | train_acc: 0.6250 | test_loss: 1.0458 | test_acc: 0.3419\n",
            " 50% 10/20 [00:21<00:22,  2.27s/it]Epoch: 11 | train_loss: 0.8756 | train_acc: 0.5430 | test_loss: 1.0223 | test_acc: 0.5047\n",
            " 55% 11/20 [00:23<00:19,  2.18s/it]Epoch: 12 | train_loss: 0.8075 | train_acc: 0.6797 | test_loss: 1.0134 | test_acc: 0.4337\n",
            " 60% 12/20 [00:25<00:17,  2.13s/it]Epoch: 13 | train_loss: 0.8220 | train_acc: 0.6250 | test_loss: 1.0106 | test_acc: 0.4839\n",
            " 65% 13/20 [00:27<00:14,  2.09s/it]Epoch: 14 | train_loss: 0.9059 | train_acc: 0.5586 | test_loss: 0.9708 | test_acc: 0.4839\n",
            " 70% 14/20 [00:29<00:12,  2.07s/it]Epoch: 15 | train_loss: 0.9036 | train_acc: 0.5195 | test_loss: 1.0302 | test_acc: 0.4242\n",
            " 75% 15/20 [00:31<00:10,  2.05s/it]Epoch: 16 | train_loss: 0.7205 | train_acc: 0.6836 | test_loss: 0.9957 | test_acc: 0.5237\n",
            " 80% 16/20 [00:33<00:08,  2.05s/it]Epoch: 17 | train_loss: 1.0412 | train_acc: 0.5117 | test_loss: 0.9501 | test_acc: 0.5246\n",
            " 85% 17/20 [00:35<00:06,  2.03s/it]Epoch: 18 | train_loss: 0.7852 | train_acc: 0.7070 | test_loss: 0.9603 | test_acc: 0.5256\n",
            " 90% 18/20 [00:37<00:04,  2.03s/it]Epoch: 19 | train_loss: 0.8430 | train_acc: 0.6250 | test_loss: 1.0147 | test_acc: 0.5047\n",
            " 95% 19/20 [00:39<00:02,  2.02s/it]Epoch: 20 | train_loss: 0.8137 | train_acc: 0.5820 | test_loss: 1.1253 | test_acc: 0.4337\n",
            "100% 20/20 [00:41<00:00,  2.08s/it]\n",
            "INFO - Total training time :41.651 seconds\n",
            "[INFO] Saving model to: models/Saved_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = model_0.load_state_dict(torch.load(\"/content/models/Saved_model.pth\"))\n",
        "img , label = train_data[20]\n",
        "loaded_model.eval()\n",
        "with torch.inference_mode():\n",
        "  y_pred = loaded_model(img.unsqueeze(dim = 0))\n",
        "print(f\"modelk predications are {class_names[y_pred.argmax(dim= 1)]}\")\n",
        "print(f\" the actual label is {class_names[label]}\")\n",
        "plt.imshow(img.permute(1,2,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "6MFvr7Hv6-Jz",
        "outputId": "a258c71b-344b-453d-d609-23b9ccfbdc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-d5769eaf3a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/models/Saved_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "loaded_model = TinyVGG(3,10,len(class_names)).to(device)\n",
        "loaded_model.load_state_dict(torch.load(\"/content/models/Saved_model.pth\"))\n",
        "img , label = train_data[random.randint(1,100)]\n",
        "loaded_model.eval()\n",
        "with torch.inference_mode():\n",
        "  y_pred = loaded_model(img.unsqueeze(dim = 0))\n",
        "print(f\"modelk predications are {class_names[y_pred.argmax(dim= 1)]}\")\n",
        "print(f\" the actual label is {class_names[label]}\")\n",
        "plt.imshow(img.permute(1,2,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "-qafsa0sR3dD",
        "outputId": "5678e871-44bc-424c-f8e8-2a0ee821a435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelk predications are pizza\n",
            " the actual label is pizza\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f272ce85bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.randint(1,100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35s4Zc7-Sf-k",
        "outputId": "cd66ca94-c373-48d7-ee0b-fb6098a1bb9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}